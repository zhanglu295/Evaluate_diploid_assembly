{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diploid assemblies (in pseudohap2 and megabubbles) from supernova 2 can be downloaded at [Mendel]( http://mendel.stanford.edu/supplementarydata/zhang_SN2_2019/). For details, please see the readme file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract contig sequences from diploid assemblies (scaffolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import re\n",
    "\n",
    "def extract_config_from_scaffold(scaffold_file,contig_file):\n",
    "    fw = open(contig_file,\"w\")\n",
    "    f =  gzip.open(scaffold_file,\"r\")\n",
    "    flag = 0\n",
    "    N10 = \"N\"*10 + \"+\"\n",
    "    step = 1\n",
    "    contig = \"\"\n",
    "    curr = 0\n",
    "    for line in f:\n",
    "        curr += 1\n",
    "        if line.decode()[0]== \">\":\n",
    "            flag = 1\n",
    "            if contig != \"\":\n",
    "                all_contigs = re.split(N10,contig)\n",
    "                for one_contig in all_contigs:\n",
    "                    fw.writelines(\">\" + str(step)+ \"\\n\")\n",
    "                    step += 1\n",
    "                    fw.writelines(one_contig + \"\\n\")\n",
    "\n",
    "                contig = \"\"\n",
    "            continue\n",
    "        if flag == 1:\n",
    "            contig += line.decode().strip(\"\\n\")\n",
    "\n",
    "    all_contigs = re.split(N10,contig)\n",
    "    for one_contig in all_contigs:\n",
    "        fw.writelines(\">\" + str(step) + \"\\n\")\n",
    "        fw.writelines(one_contig + \"\\n\")\n",
    "        step+=1\n",
    "    print(\"finished\")\n",
    "extract_config_from_scaffold(\"L6_SN2.fasta.gz\",\"L6_SN2_contig.fasta\")\n",
    "extract_config_from_scaffold(\"L7_SN2.fasta.gz\",\"L7_SN2_contig.fasta\")\n",
    "extract_config_from_scaffold(\"L8_SN2.fasta.gz\",\"L8_SN2_contig.fasta\")\n",
    "extract_config_from_scaffold(\"L9_SN2.fasta.gz\",\"L9_SN2_contig.fasta\")\n",
    "extract_config_from_scaffold(\"L10_SN2.fasta.gz\",\"L10_SN2_contig.fasta\")\n",
    "extract_config_from_scaffold(\"L11_SN2.fasta.gz\",\"L11_SN2_contig.fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate .info files\n",
    ".info file(three columns: scaffold id, contig id, order of contig in the scaffold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import re\n",
    "\n",
    "def extract_config_info(scaffold_file,info_file):\n",
    "    fw = open(info_file,\"w\")\n",
    "    f = gzip.open(scaffold_file,\"r\")\n",
    "    flag = 0\n",
    "    N10 = '('+\"N\"*10 + \"+\"+')'\n",
    "    step = 1\n",
    "    scaffold_num = 1\n",
    "    contig = \"\"\n",
    "    curr = 0\n",
    "    for line in f:\n",
    "        curr += 1\n",
    "        if line.decode()[0]== \">\":\n",
    "            flag = 1\n",
    "            if contig != \"\":\n",
    "                all_contigs = re.split(N10,contig)\n",
    "                order = 1\n",
    "                for i in range(len(all_contigs)):\n",
    "                    if i%2==0:\n",
    "                        if i==len(all_contigs)-1:\n",
    "                            fw.write(str(scaffold_num) + \"\\t\" + str(step)+\"\\t\"+ str(order)+\"\\t\"+str(0)+'\\n')\n",
    "                            order+=1\n",
    "                            step+=1\n",
    "                        else:\n",
    "                            fw.write(str(scaffold_num) + \"\\t\" + str(step)+\"\\t\"+ str(order)+\"\\t\")\n",
    "                    else:\n",
    "                        fw.write(str(len(all_contigs[i]))+'\\n')\n",
    "                        order+=1\n",
    "                        step+=1\n",
    "                contig = \"\"\n",
    "                scaffold_num += 1\n",
    "            continue\n",
    "        if flag == 1:\n",
    "            contig += line.decode().strip(\"\\n\")\n",
    "\n",
    "    all_contigs = re.split(N10,contig)\n",
    "    order = 1\n",
    "    for i in range(len(all_contigs)):\n",
    "        if i%2==0:\n",
    "            if i==len(all_contigs)-1:\n",
    "                fw.write(str(scaffold_num) + \"\\t\" + str(step)+\"\\t\"+ str(order)+\"\\t\"+str(0)+'\\n')\n",
    "                order+=1\n",
    "                step+=1\n",
    "            else:\n",
    "                fw.write(str(scaffold_num) + \"\\t\" + str(step)+\"\\t\"+ str(order)+\"\\t\")\n",
    "        else:\n",
    "            fw.write(str(len(all_contigs[i]))+'\\n')\n",
    "            order+=1\n",
    "            step+=1\n",
    "    f.close()\n",
    "    fw.close()\n",
    "    print(\"finished\")\n",
    "\n",
    "extract_config_info(\"L6_SN2.fasta.gz\",\"L6_SN2.info\")\n",
    "extract_config_info(\"L7_SN2.fasta.gz\",\"L7_SN2.info\")\n",
    "extract_config_info(\"L8_SN2.fasta.gz\",\"L8_SN2.info\")\n",
    "extract_config_info(\"L9_SN2.fasta.gz\",\"L9_SN2.info\")\n",
    "extract_config_info(\"L10_SN2.fasta.gz\",\"L10_SN2.info\")\n",
    "extract_config_info(\"L11_SN2.fasta.gz\",\"L11_SN2.info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run [quast](http://quast.sourceforge.net/quast) to generate basic statistics, including Contig N50, NA50 and Scaffold N50 and contig alignment files (all\\_alignments_*_contig.tsv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quast.py L6_SN2_contig.fasta --extensive-mis-size 100 --threads 40 --fast --no-snps --min-alignment 200 -R Homo_sapiens_ref.fa -o quast_contig_L6\n",
    "\n",
    "quast.py L7_SN2_contig.fasta --extensive-mis-size 100 --threads 40 --fast --no-snps --min-alignment 200 -R Homo_sapiens_ref.fa -o quast_contig_L7\n",
    " \n",
    "quast.py L8_SN2_contig.fasta --extensive-mis-size 100 --threads 40 --fast --no-snps --min-alignment 200 -R Homo_sapiens_ref.fa -o quast_contig_L8\n",
    "  \n",
    "quast.py L9_SN2_contig.fasta --extensive-mis-size 100 --threads 40 --fast --no-snps --min-alignment 200 -R Homo_sapiens_ref.fa -o quast_contig_L9\n",
    "   \n",
    "quast.py L10_SN2_contig.fasta --extensive-mis-size 100 --threads 40 --fast --no-snps --min-alignment 200 -R Homo_sapiens_ref.fa -o quast_contig_L10\n",
    "    \n",
    "quast.py L11_SN2_contig.fasta --extensive-mis-size 100 --threads 40 --fast --no-snps --min-alignment 200 -R Homo_sapiens_ref.fa -o quast_contig_L11\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Calculate Scaffold NA50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "python denovo_stat.py -t all_alignments_L6_SN2_contig.tsv -c L6_SN2_contig.fasta -s L6_SN2.fasta.gz -r Homo_sapiens_ref.fa -i L6_SN2.info -p L6_stat -o ./\n",
    "python denovo_stat.py -t all_alignments_L7_SN2_contig.tsv -c L7_SN2_contig.fasta -s L7_SN2.fasta.gz -r Homo_sapiens_ref.fa -i L7_SN2.info -p L7_stat -o ./\n",
    "python denovo_stat.py -t all_alignments_L8_SN2_contig.tsv -c L8_SN2_contig.fasta -s L8_SN2.fasta.gz -r Homo_sapiens_ref.fa -i L8_SN2.info -p L8_stat -o ./\n",
    "python denovo_stat.py -t all_alignments_L9_SN2_contig.tsv -c L9_SN2_contig.fasta -s L9_SN2.fasta.gz -r Homo_sapiens_ref.fa -i L9_SN2.info -p L9_stat -o ./\n",
    "python denovo_stat.py -t all_alignments_L10_SN2_contig.tsv -c L10_SN2_contig.fasta -s L10_SN2.fasta.gz -r Homo_sapiens_ref.fa -i L10_SN2.info -p L10_stat -o ./\n",
    "python denovo_stat.py -t all_alignments_L11_SN2_contig.tsv -c L11_SN2_contig.fasta -s L11_SN2.fasta.gz -r Homo_sapiens_ref.fa -i L11_SN2.info -p L11_stat -o ./\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Extract contigs from megabubbles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "for index in ['L6','L7','L8','L9','L10','L11']:\n",
    "    fasta=defaultdict(list)\n",
    "    totalscaffold=0\n",
    "    totaldiploid=0\n",
    "    infile=gzip.open(index+'_SN2_megabubble.fasta.gz')\n",
    "    outfile=open(index+'_diploid_scaffold.fasta','w')\n",
    "    key=''\n",
    "    value=''\n",
    "    linenum=0\n",
    "    for line1 in infile:\n",
    "        line=line1.decode()\n",
    "        if line[0]=='>':\n",
    "            #print(line)\n",
    "            A=line.strip('\\n').split(' ')\n",
    "            if linenum==0:\n",
    "                key=A[2]+' '+A[3]\n",
    "                totalscaffold+=1\n",
    "            else:\n",
    "                fasta[key].append(value)\n",
    "                key=A[2]+' '+A[3]\n",
    "                value=''\n",
    "                totalscaffold+=1\n",
    "        else:\n",
    "            value=value+line.strip('\\n')\n",
    "        linenum+=1\n",
    "    fasta[key].append(value)\n",
    "    contigid=0\n",
    "    for key,value in fasta.items():\n",
    "        if len(value)==2:\n",
    "            outfile.write('>'+str(contigid)+' '+key+'\\n')\n",
    "            outfile.write(value[0]+'\\n')\n",
    "            contigid+=1\n",
    "            outfile.write('>'+str(contigid)+' '+key+'\\n')\n",
    "            outfile.write(value[1]+'\\n')\n",
    "            contigid+=1\n",
    "            totaldiploid+=2\n",
    "        elif len(value)>2:\n",
    "            print('SB')\n",
    "    infile.close()\n",
    "    outfile.close()\n",
    "    print(index+'\\n')\n",
    "    print('totalscaffold '+str(totalscaffold)+'\\n')\n",
    "    print('totaldiploid '+str(totaldiploid)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "#pdb.set_trace()\n",
    "import gzip\n",
    "import re\n",
    "\n",
    "def extract_config_from_megabubble_fasta(megabubble_file,contig_file):\n",
    "    fw = open(contig_file,\"w\")\n",
    "    f =  open(megabubble_file,\"r\")\n",
    "    flag = 0\n",
    "    N100 = \"N\"*10 + \"+\"\n",
    "    step = 1\n",
    "    contig = \"\"\n",
    "    curr = 0\n",
    "    for line in f:\n",
    "        curr += 1\n",
    "        if line[0]== \">\":\n",
    "            flag = 1\n",
    "            # process the previous one\n",
    "            if contig != \"\":\n",
    "                all_contigs = re.split(N100,contig)\n",
    "                for one_contig in all_contigs:\n",
    "                    fw.writelines(\">\" + str(step)+ \"\\n\")\n",
    "                    step += 1\n",
    "                    fw.writelines(one_contig + \"\\n\")\n",
    "\n",
    "                contig = \"\"\n",
    "            continue\n",
    "        if flag == 1:\n",
    "            contig += line.strip(\"\\n\")\n",
    "\n",
    "    all_contigs = re.split(N100,contig)\n",
    "    for one_contig in all_contigs:\n",
    "        fw.writelines(\">\" + str(step) + \"\\n\")\n",
    "        fw.writelines(one_contig + \"\\n\")\n",
    "        step+=1\n",
    "    print(\"finished\")\n",
    "extract_config_from_megabubble_fasta(\"L6_diploid_scaffold.fasta\",\"L6_diploid_contig.fasta\")\n",
    "extract_config_from_megabubble_fasta(\"L7_diploid_scaffold.fasta\",\"L7_diploid_contig.fasta\")\n",
    "extract_config_from_megabubble_fasta(\"L8_diploid_scaffold.fasta\",\"L8_diploid_contig.fasta\")\n",
    "extract_config_from_megabubble_fasta(\"L9_diploid_scaffold.fasta\",\"L9_diploid_contig.fasta\")\n",
    "extract_config_from_megabubble_fasta(\"L10_diploid_scaffold.fasta\",\"L10_diploid_contig.fasta\")\n",
    "extract_config_from_megabubble_fasta(\"L11_diploid_scaffold.fasta\",\"L11_diploid_contig.fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Calculate the proportion of genome is assembled in two haplotypes by [mosdepth](https://github.com/brentp/mosdepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minimap2 -a Homo_sapiens_ref.mmi L6_diploid_contig.fasta | samtools view -Sb -| samtools sort -o L6_diploid_align.bam\n",
    "samtools index L6_diploid_align.bam\n",
    "minimap2 -a Homo_sapiens_ref.mmi L7_diploid_contig.fasta | samtools view -Sb -| samtools sort -o L7_diploid_align.bam\n",
    "samtools index L7_diploid_align.bam\n",
    "minimap2 -a Homo_sapiens_ref.mmi L8_diploid_contig.fasta | samtools view -Sb -| samtools sort -o L8_diploid_align.bam\n",
    "samtools index L8_diploid_align.bam\n",
    "minimap2 -a Homo_sapiens_ref.mmi L9_diploid_contig.fasta | samtools view -Sb -| samtools sort -o L9_diploid_align.bam\n",
    "samtools index L9_diploid_align.bam\n",
    "minimap2 -a Homo_sapiens_ref.mmi L10_diploid_contig.fasta | samtools view -Sb -| samtools sort -o L10_diploid_align.bam\n",
    "samtools index L10_diploid_align.bam\n",
    "minimap2 -a Homo_sapiens_ref.mmi L11_diploid_contig.fasta | samtools view -Sb -| samtools sort -o L11_diploid_align.bam\n",
    "samtools index L11_diploid_align.bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mosdepth -t 4 -Q 20 -n --by 500 L6_coverage L6_diploid_align.bam\n",
    "mosdepth -t 4 -Q 20 -n --by 500 L7_coverage L7_diploid_align.bam\n",
    "mosdepth -t 4 -Q 20 -n --by 500 L8_coverage L8_diploid_align.bam\n",
    "mosdepth -t 4 -Q 20 -n --by 500 L9_coverage L9_diploid_align.bam\n",
    "mosdepth -t 4 -Q 20 -n --by 500 L10_coverage L10_diploid_align.bam\n",
    "mosdepth -t 4 -Q 20 -n --by 500 L11_coverage L11_diploid_align.bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "diploid=0\n",
    "allwin=0\n",
    "for index in ['L6','L7','L8','L9','L10','L11']:\n",
    "    infile=gzip.open(index+'_coverage.regions.bed.gz')\n",
    "    for line in infile:\n",
    "        A=line.decode().strip('\\n').rsplit()\n",
    "        if A[0]!='X':\n",
    "            allwin+=1\n",
    "            if A[3]=='2.00':\n",
    "                diploid+=1\n",
    "    print(diploid/allwin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
